## 卷积神经网络

卷积神经网络主要由输入层、卷积层、ReLU层、池化层和全连接层组成



### 一、输入层

传入数据处理层，一般是对图像进行resize和归一化，以符合神经网络的需求



#### 二、卷积层与ReLU层

在实际运用中，卷积层与ReLU层经常放在一起使用，即在卷积之后运用Relu作为激活函数对卷积层的输出进行处理



1. 主要作用：使用卷积核(滤波器)对输入图像进行卷积运算和特征提取

2. 重要参数：卷积核大小、卷积核数量、步长、零填充、卷积核权值

   - 卷积核大小决定神经元的感受野，有3X3、5X5或7X7,卷积核越大，计算量越大
   - 卷积核数量决定卷积层输出的深度，即输出的图像特征层数
   - 步长控制卷积核(滤波器)每次滑动的像素，当步长为1，滤波器每次移动1个像素；当步长为2，滤波器滑动时每次移动2个像素(步长也可以是不常用的3，或者更大的数字，但这些在实际中很少使用)，步长决定输出数据的长宽尺寸
   - 零填充是对输入数据体的边缘用0填充，通常是为了保持输入数据体的长宽尺寸，使输入和输出的长宽相等
   - 卷积核权值决定对图像卷积计算的方式，卷积权值一般是通过训练进行学习生成

   **卷积核数量、步长和零填充决定输出数据的尺寸**

3. 在数据卷积之后，使用relu函数对输出数据进行处理，ReLU是一个激活函数，卷积神经网络中，使用该函数的作用是去除卷积结果中的负值，保留正值不变



#### 三、池化层

1. 主要作用：对卷积处理的数据进行采样，缩小到更小的尺寸，以压缩数据和参数数量，减小过拟合，提高模型的容错性。
2. 重要参数：池化窗口大小、步幅、池化方法
   - 池化窗口大小通常为2或3
   - 步幅通常是2
   - 池化方法分三种：最大值池化、平均值池化、权值池化



#### 四、全连接层

1. 主要作用：是实际分类的一层，对接受的图片特征值进行训练分类
2. 重要参数：激活函数选择，对应不同的分类问题，有不同的激活函数选择
   - 二分类问题：使用Sigmoid函数，如判断目标是否为水稻，返回是水稻的概率
   - 多分类问题：使用softmax函数，返回每一类的概率，概率总和为1
   - 线性回归问题：使用线性函数作为激活函数



### VGG19

![img](https://img-blog.csdnimg.cn/img_convert/8d5919d841ca662ede0b04012231ee5a.png)



![Illustration of the network architecture of VGG-19 model: conv means... |  Download Scientific Diagram](https://img-blog.csdnimg.cn/img_convert/7ee5eee61be3dd136a47f1b449579570.png)







